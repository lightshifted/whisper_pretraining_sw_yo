# Wednesday, December 7th, 2022

### üèπ Day's Tasks

* Complete training pipeline on Google Colab Notebook using the HuggingFace Transformer library.
* Prepare whisper-small-sw weights for upload to HuggingFace repository.
* Construct preprocessing pipelines for training with local data, utilizing the TensorFlow framework and the NVIDIA A100 GPU on Lambda Cloud for efficient training.
* Complete analysis of on-hand datasets contained in resources.md, using Pandas and NumPy for efficient data manipulation and analysis. The resources file must be ready by tomorrow for upload to GitHub repository at the end of that day's work.


### üéØ Progress Made

* I successfully implemented the HuggingFace Transformer library on a Google Colab notebook, achieving impressive results on the Swahili subset of the Common Voices 11 dataset. I also utilized the ssh connection with Lambda Cloud GPU for access to the NVIDIA A100, allowing for efficient training of the model.
* I have successfully prepared the whisper-small-sw weights and uploaded them to the HuggingFace repository, making them readily available for other researchers to utilize.

### üìÉ Work for December 8th, 2022
* In order to properly preprocess the local data for training, I will research the best methods for converting audio and text data into the appropriate formats (.tar and .tsv files, respectively) utilizing the TensorFlow framework and the NVIDIA A100 GPU on Lambda Cloud for efficient training.


### üí° Principals Learned
* The power of utilizing state-of-the-art libraries and technologies, such as HuggingFace and NVIDIA A100, for machine learning projects cannot be understated. By utilizing these tools, I was able to make impressive progress on my project and achieve high-quality results.
