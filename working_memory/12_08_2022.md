# Thursday, December 8th, 2022

### üèπ Day's Tasks

* Complete analysis of on-hand datasets contained in resources.md, using Pandas and NumPy for efficient data manipulation and analysis. The resources file must be ready by tomorrow for upload to GitHub repository at the end of that day's work.
* Construct data preprocessing pipelines for Babel Swahili Language Pack and KenSpeech datasets. This requires a script that can take timestamped utterances and convert into format compatible with training on Whisper model.
* Save model from Lambda Cloud GPU run onto local machine using ssh.

### üéØ Progress Made

* There are now two scripts in the whisper_event project folder: `install_ffmpeg_env.py` and `install_venv_env.py`. These scripts are used together to speed up the setup process for setting up the community-events environment in Lambda GPU Cloud instance.
* There's now a notebook `gather_local_data.ipynb` containing code for preprocessing audio and transcription files from the `babel_swahili_language_pack` dataset. 
* I wrote code that's used to extract timestamps and utterances from a text file and group them into 30-second intervals. It does this by reading the lines of a text file, checking whether each line is a timestamp or an utterance, and then storing the timestamps and utterances in separate lists. When the current timestamp exceeds 30 seconds, the code combines the timestamps and utterances into a single group and appends it to the groups list. This process is repeated until all lines in the text file have been processed. The resulting groups of timestamps and utterances are stored in the groups list.
* Wrote code that is used to split a set of .wav files into segments based on a list of segments. It does this by first gathering the file paths of all .wav files in a specified directory and storing them in the `file_paths` list. Then, for each file path in the `file_paths` list, the code opens the corresponding .wav file, extracts the audio data, and splits it into segments based on the `segments` list. For each segment, the code creates a new .wav file and writes the segment data to it. Before creating the new .wav files, the code checks if the directory they will be stored in exists. If the directory does not exist, it is created. The resulting segmented .wav files are stored in the specified directory, with names that indicate which original .wav file they were generated from and the segment index.
* Completed training of whisper-small-sw on Community Voices and Google Fluers datasets. Uploaded model to HuggingFace repository.
* Created HuggingFace space for interacting with Swahili Whisper demo. 

### üìÉ Work for December 8th, 2022

* Complete preprocessing of all Swahili datasets.
* Finalize the script for Gradio demo on HuggingFace space.
* Complete training of whisper-large-v2-sw and upload model to HuggingFace
* Read and review the project README.md for potential changes.
* Work on solving the audio and transcript interval split. Much work has been done torwards this effort, however work still remains.
* Modify model storage file structure so it's streamlined for easier loading during training runs.
* Finalize training pipeline for locally stored data
* Review steps for accessing Whisper community-event leaderboard.

### üí° Principals Learned
* Reviewing the day's accomplishments and work remaining each night is paramount to achieving my goals.
