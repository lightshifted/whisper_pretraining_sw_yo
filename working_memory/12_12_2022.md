# Monday, December 12th, 2022

### üèπ Day's Tasks
* Select 2 contractors for market research position posted on Upwork. Review Proposals.
* Complete fine-tuning of Whisper on medium sized weights using custom dataset.

### üéØ Progress Made
* [Done] Finalize the script for Gradio demo on HuggingFace space.
* [Done] Complete training of whisper-large-v2-sw and upload model to HuggingFace
* [Done] Review steps for accessing Whisper community-event leaderboard.
* [Done] Complete preprocessing of all Swahili datasets.
* [Done] Work on solving the audio and transcript interval split. Much work has been done torwards this effort, however work still remains.
* [Done] Modify model storage file structure so it's streamlined for easier loading during training runs.
* [Done] Finalize training pipeline for locally stored data
* [Done] Replace "</s>" with "" in dataset `kenspeech.txt` 
* [Done] Normalize `kenspeech.txt` and `babel.txt` datasets (e.g. remove start and end special tokens, punctuation, and certain special characters.)
* [Done] Add dropout to Lambda Cloud fine-tuning run by setting `model.config.dropout = 0.1


### üìÉ Work for December 13th, 2022


### üí° Notes / Ideas
* Reviewing the day's accomplishments and work remaining each night is paramount to achieving my goals.
* Each morning, review my list of the day's tasks and craft a daily plan incorporating them.
* Common Voice 11.0 and Google Fleurs corpora are normalized. KenSpeech, Broadcast News, and Babel corpora contain special tokens. Our model will be fine-tuned on the former datasets first. Then, we will train it on the latter corpora.