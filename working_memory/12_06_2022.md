# Tuesday, December 6th, 2022
Today, I...

### üèπ Day's Tasks

* Pass DatasetLoader class through chatgpt for code additions enabling interactions through CLI.
* Investigate error concerning the downloading of Common Voices 11 Swahili corpus using Huggingface dataset import (follow-up: I've made progresses identifying the source of the error: I did not update the Unix package ffmpeg to version 4. Doing so seems to have resolved the issue...). The next step is installing ffmpeg4 on my local Windows machine.
* Wrap normalization function into DatasetLoader class
* Complete DataLoader class and begin designing a training loop optimized for speed and low memory. Implement CLI interactivity in training loop script.
* Establish SSH connection to Lambda Cloud GPU and initiaite first training run on CommonVoice and Fluers interleaved datasets harnessing HuggingFace's datastream utility.
* Complete analysis of on-hand datasets contained in `resources.md`. Anlaysis needs to include total hours, number of speakers (by gender, age, etc. where available), and any other relevant features. The resources file must be ready by tomorrow for upload to GitHub repository at the end of that day's work.
* Modify setup script to include option to set up virtual environment through CLI.

### üéØ Progress Made

* I discovered the root cause of the error when trying to load the Swahili subset of the Common Voices 11 dataset. I was unable to fix the issue on my local machine, so I created a Colab notebook to use specifically for training with HuggingFace data. You can access the notebook here: https://colab.research.google.com/drive/19MhEE83dvbDvIBofkH7SncNH4cqk5AKe#scrollTo=maE8jAcNphRE.
* Constructed `NormalizeTranscriptions` that can be used to normalize a batch of transcriptions. The class accepts two optional arguments, `do_lower_case` and `do_remove_punctuation`, which control whether the transcriptions should be converted to lower case and whether punctuation marks should be removed from the transcriptions.
* Updated `StreamDatasetLoader` class can be used for partial dataset loading of datasets from HuggingFace ü§ó library.'
* Set-up pipeline in `whisper_event_.ipynb` Colab Notebook for mounting GCP Bucket. Good for backing up model weights.

When the class is called, it applies these optional pre-processing steps to each transcription in the batch and returns the updated batch. The code also creates an instance of the `NormalizeTranscriptions` class and uses it to normalize a stream of transcription data.

### ‚≠ê Work for December 7th, 2022
* Complete training pipeline on Google Colab Notebook.
* Prepare whisper-small-sw weights for upload to HuggingFace repository.
* Construct preprocessing pipelines for training with local data. Will train through CLI.
* Complete analysis of on-hand datasets contained in `resources.md`. Anlaysis needs to include total hours, number of speakers (by gender, age, etc. where available), and any other relevant features. The resources file must be ready by tomorrow for upload to GitHub repository at the end of that day's work.
* Modify setup script to include option to set up virtual environment through CLI.
* Establish SSH connection to Lambda Cloud GPU and initiaite first training run on CommonVoice and Fluers interleaved datasets harnessing HuggingFace's datastream utility.

### üî≠ Principals Learned

* The _stream_ method of `load_dataset` class throws an error when setting language code to "sw" for Swahili. The same error is not encountered when loading English dataset, however. Have not tested enough to know if the issue is limited to certain data subsets, but worth investigating further. **Correction** error is encountered even when stream method is turned off.
* It's important to follow all steps of a README.md, especially when the project is using a mixture of complex libraries.
