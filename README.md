# Whisper Pretraining

In this project, we will fine-tune the Whisper model to build state-of-the art speech recognition systems in the Swahili and Yoruba languages. Our final model will be evaluated on the "test" split of the [Common Voice 11](https://huggingface.co/datasets/mozilla-foundation/common_voice_11_0) dataset for our chosen languages.

## Overview

### Important Dates

- *Introduction Talk*: 2nd December 2022
- *Sprint start*: 5th December 2022
- *Speaker Events*: 5th December 2022
- *Sprint end*: 19th December 2022
- *Results*: 23rd December 2022

### Goals and Objectives

The main goal of this project is to fine-tune the Whisper model to build state-of-the-art speech recognition systems in the Swahili and Yoruba languages.

Our objectives are as follows:

- To *improve* the accuracy of speech recognition in the Swahili and Yoruba languages by fine-tuning the Whisper model using a large dataset of audio samples in these languages.

- To *develop* a user-friendly interface for the speech recognition system that allows users to easily interact with the model and obtain accurate transcription of their speech in real-time.

- To *integrate* the fine-tuned Whisper model into existing speech recognition applications and platforms to expand their capabilities and make them more accessible to users of the Swahili and Yoruba languages.

- To *create* a community of users and developers who can contribute to the project by providing feedback, suggestions, and additional data to further improve the performance of the speech recognition system.

By achieving these objectives, we aim to make a significant contribution to the field of speech recognition and improve access to information and communication for speakers of the Swahili and Yoruba languages.

### Project Plan

Our plan for fine-tuning the Whisper model is as follows:

#### Week 1 (5th December 2022)

- Conduct initial research on the structure and characteristics of the Swahili and Yoruba languages
- Identify any unique challenges or opportunities for building speech recognition systems for these languages
- Begin fine-tuning the Whisper model using a small dataset of Swahili and Yoruba speech data
- Monitor and adjust the model as needed to optimize its performance on these languages

#### Week 2 (12th December 2022)

- Expand the dataset to include a wider range of voices and accents in both languages

#### Week 3 (19th December 2022)

- Monitor and adjust the model as needed to optimize its performance on these languages

## How to Contribute

If you are interested in contributing to this project, there are several ways you can help:

- Provide feedback and suggestions on the performance of the speech recognition system.
- Offer additional data for fine-tuning the Whisper model.
- Join the community of users and developers to discuss and collaborate on the project.

### Branching Strategy

Only well-tested and reviewed code is merged into the master branch. This helps to avoid merge conflicts and ensures the quality of the codebase.

**Steps:**

1. Create a new branch for each feature or bug fix, based on the master branch.
2. Develop and test the feature or fix in the branch.
3. Create a pull request to merge the branch into the master branch.
4. Review the changes in the pull request and discuss any issues or suggestions with the team.
5. If there are no conflicts, we'll merge the branch into the master branch.
6. If there are conflicts, resolve them in the branch and create a new pull request for our review.
7. Repeat the process for each new feature or bug fix.

To get started, fork this repository and submit a pull request with your proposed changes. We look forward to working with you to improve the accuracy of speech recognition in the Swahili and Yoruba languages!
